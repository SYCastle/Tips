# 1.機械学習の現状


## 1.1 機械学習とは何か

- コンピュータがデータから学習できるようにするためのコンピュータプログラミングについての科学


## 1.2 なぜ機械学習を使うのか

- 既存のソリューションでは、手作業による大量のチューニングや、ルールの長いリストが必要な問題に対して有効
    - ex.) スパムメールのフィルタを、機械学習を使わないで実現する場合、「～なタイトルの場合、またはリンクが書かれている～」とスパムの特徴をルールベースで大量に記述。メンテナンス性と正確性に欠ける。

## 1.3 機械学習システムのタイプ

大きく以下に分類される

- 人間の関与のもとで訓練されるかどうか(教師あり、教師なし、半教師あり、強化学習)
- その場で少しずつ学習できるかどうか(オンライン、バッチ学習)
- 単純に新しいデータポイントと既知のデータポイントを比較するか、科学者が行うように訓練データからパターンを見つけ出して予測モデルを構築するか(インスタンスベース、モデルベース学習)

### 1.3.1 教師あり/教師なし学習

#### 1.3.1.1 教師あり学習

- 教師あり機械学習のタスクとしてまず思いつくのが分類
    - ex.) スパムメールフィルタ。クラス付け(スパムかそうでないか)された大量のデータを訓練

- また、一連の特徴量(ex.走行距離、使用年数...etc)からターゲットのラベルである数値(ex.中古車の価格)を予測する回帰と呼ばれるタスクでも使われる


重要な教師あり学習アルゴリズムの一部を以下に挙げる

- k近傍法
- 線形回帰(4章)
- ロジスティクス回帰(4章)
- サポートベクターマシーン(5章)
- 決定木とランダムフォレスト(6,7章)
- ニューラルネットワーク(10章)

#### 1.3.1.2 教師なし学習

- 訓練データにラベルがついていない

重要な教師なし学習アルゴリズムの一部を以下に挙げる(詳細は8章等)

- クラスタリング(ex.ブログの訪問者について、類似する集団分けができる。40%の訪問者は漫画好きの男性で夜中にブログを読んでいる...etc)
    - k平均
    - 階層型クラスタ分析
    - EMアルゴリズム
- 可視化と次元削減(ex.可視化のアウトプットは、プロットしやすい2次元/3次元データであり、プロットすることでデータの分布等のパターンを目視できる。次元削減(情報を損なわず、データを単純化)も併用される)
    - 主成分分析(ex.車の走行距離は、使用年数と非常に高い相関を示すため、これら2つの情報を1つにまとめる)
    - カーネルPCA
    - LLE(Locally-Linier Embedding:局所線形埋め込み)
    - t-SNE(t-distributed stochastic neighbor embedding:t分布型確率的近傍埋め込み法)
- 相関ルール学習
    - アプリオリ
    - eclat

教師なし学習の重要なタスクとして、以下が挙げられる

- 異常検知
    - ex.異常なクレジットカード取引の発見
- 相関ルール学習(大量のデータを掘り下げて、属性の間から面白い関係を見つけ出す)
    - ex.スーパーマーケットの購買データから、「バーベキューソースとポテトチップスを買う人はステーキ肉も買っていることがわかるので、それらの商品を近くに配置する」etc

#### 1.3.1.3 半教師あり学習

- 一部だけラベルが付けられたデータを扱う
    - ex.Google Photosのように、アップロードした写真の人のが誰なのか分類/検索できる。まず教師なし学習(クラスタリング)により、人物Aは写真No1,5,11、人物Bは写真No2,5,7に写っていることが分かり、ラベル付き教師データ(人物A/Bがそれぞれ誰なのか)を提供されることで、写真に写っている人が誰なのか分かる。

ほとんどの半教師あり学習は、教師なし学習アルゴリズムと教師あり学習アルゴリズムを結合したもの。
ex.DBN(Deep Breaf Net)は制限付きボルツマンマシン(RBM)という教師なしコンポーネントを積み上げたもの。

#### 1.3.1.4 強化学習

- ex.囲碁 (AlphaGo)
- 学習システム(エージェント)は、環境を観察し、行動を選択して実行し、より良い報酬を得るように、方策(policy)と呼ばれる戦略を自分で学習していく

### 1.3.2 バッチ学習とオンライン学習





### 1.3.3 インスタンスベース学習とモデルベース学習

## 1.4 機械学習が抱える難関

### 1.4.1 訓練データ例の品質の低さ


### 1.4.2 現実を代表しているとは言えない訓練データ


### 1.4.3 品質の低いデータ


### 1.4.4 無関係な特徴量


### 1.4.5 訓練データへの過学習

### 1.4.6 訓練データへの過小適合


### 1.4.7 一歩下がって復習しよう


## 1.5 テストと検証


## 1.6 演習問題
